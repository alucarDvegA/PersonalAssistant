{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76109adb",
   "metadata": {},
   "source": [
    "[MIT License]\n",
    "\n",
    "PyAudio is distributed under the MIT License:\n",
    "Copyright (c) 2006 Hubert Pham\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce07cb74",
   "metadata": {},
   "source": [
    "[PIL Software License]\n",
    "\n",
    "The Python Imaging Library (PIL) is\n",
    "Copyright © 1997-2011 by Secret Labs AB\n",
    "Copyright © 1995-2011 by Fredrik Lundh\n",
    "By obtaining, using, and/or copying this software and/or its associated documentation, you agree that you have read, understood, and will comply with the following terms and conditions:\n",
    "Permission to use, copy, modify, and distribute this software and its associated documentation for any purpose and without fee is hereby granted, provided that the above copyright notice appears in all copies, and that both that copyright notice and this permission notice appear in supporting documentation, and that the name of Secret Labs AB or the author not be used in advertising or publicity pertaining to distribution of the software without specific, written prior permission.\n",
    "SECRET LABS AB AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL SECRET LABS AB OR THE AUTHOR BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cff0636",
   "metadata": {},
   "source": [
    "[3-clause BSD License]\n",
    "\n",
    "Copyright (c) 2014-2017, Anthony Zhang <azhang9@gmail.com>\n",
    "All rights reserved.\n",
    "Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n",
    "1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\n",
    "2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\n",
    "3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n",
    "\n",
    "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "908b0dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  #VOICEVOXを忘れずに起動する事！\n",
    "# # 各種ライブラリインストール\n",
    "    \n",
    "# !pip install --upgrade pip\n",
    "# !pip install pyaudio    \n",
    "# !pip install openai\n",
    "# !pip install --upgrade openai \n",
    "# !pip show openai\n",
    "\n",
    "# !pip install SpeechRecognition\n",
    "# !pip install Pillow\n",
    "\n",
    "# !pip install pyinstaller#実行ファイル作成用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c954929d-7bdd-4f8b-81b1-c13b9fa89ad7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c954929d-7bdd-4f8b-81b1-c13b9fa89ad7",
    "outputId": "79031712-e113-4dc5-dbfa-7ecd2b141021",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#chatGPT\n",
    "import openai\n",
    "openai.api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43304a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #合成した音声を出力するための関数を定義（after関数）\n",
    "# import pyaudio\n",
    "# import wave\n",
    "# import time\n",
    "\n",
    "# def update_image(nurse_now):\n",
    "#     if nurse_now == \"o\":canvas.create_image(-scrw/20, 0, anchor=tk.NW, image=nurse_o)\n",
    "#     if nurse_now == \"n\":canvas.create_image(-scrw/20, 0, anchor=tk.NW, image=nurse_n)\n",
    "#     canvas.update_idletasks()\n",
    "#     print(nurse_now)\n",
    "#     print(\"OK\")\n",
    "        \n",
    "# def play_wav():\n",
    "#     canvas.create_image(-scrw/20, 0, anchor=tk.NW, image=nurse_o)#一口目\n",
    "#     canvas.update()\n",
    "#     CHUNK = 1024\n",
    "\n",
    "#     wf = wave.open(\"audio.wav\", 'rb')\n",
    "#     p = pyaudio.PyAudio()\n",
    "\n",
    "#     stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\n",
    "#                     channels=wf.getnchannels(),\n",
    "#                     rate=wf.getframerate(),\n",
    "#                     output=True)\n",
    "#     data = wf.readframes(CHUNK)\n",
    "#     c=0\n",
    "#     nurse_prev = \"\"\n",
    "#     while data:\n",
    "#         rms = 0.0  # 瞬時の音量を計算するための変数\n",
    "#         # データがバイト列として与えられるため、16ビットの整数に変換してから処理する\n",
    "#         for i in range(0, len(data), 2):\n",
    "#             sample = int.from_bytes(data[i:i+2], byteorder=\"little\", signed=True)\n",
    "#             rms += sample ** 2\n",
    "#         rms /= CHUNK\n",
    "#         rms = rms ** 0.5  # 平均平方根 (RMS)\n",
    "#         if c%8 == 0:\n",
    "#             print(rms)\n",
    "\n",
    "#             if rms > 500:  # 音量が大きい場合は nurse_o を表示\n",
    "#                 nurse_now = \"o\"\n",
    "#                 #print(nurse_now)\n",
    "#                 if nurse_prev != nurse_now:canvas.after(8, update_image,nurse_now)                \n",
    "#             else:  # 音量が小さい場合は nurse_n を表示\n",
    "#                 nurse_now = \"n\"\n",
    "#                 #print(nurse_now)\n",
    "#                 if nurse_prev != nurse_now:canvas.after(8, update_image,nurse_now)\n",
    "#             #if nurse_prev != nurse_now:canvas.update()\n",
    "#             nurse_prev = nurse_now\n",
    "#         stream.write(data)\n",
    "#         data = wf.readframes(CHUNK)\n",
    "#         c+=1\n",
    "#     canvas.create_image(-scrw/20, 0, anchor=tk.NW, image=nurse_n)#口閉じる\n",
    "#     canvas.update()\n",
    "#     stream.stop_stream()\n",
    "#     stream.close()\n",
    "#     p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "926254d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#合成した音声を出力するための関数を定義（逆転マルチスレッド）\n",
    "import pyaudio\n",
    "import wave\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "\n",
    "# Queueオブジェクトの生成\n",
    "q = queue.Queue()\n",
    "q.put(\"n\")            \n",
    "def play_stream():\n",
    "    CHUNK = 1024\n",
    "\n",
    "    wf = wave.open(\"audio.wav\", 'rb')\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\n",
    "                    channels=wf.getnchannels(),\n",
    "                    rate=wf.getframerate(),\n",
    "                    output=True)\n",
    "    data = wf.readframes(CHUNK)#１音目を発声\n",
    "    c = 0\n",
    "    nurse_now = \"n\"\n",
    "    while data:\n",
    "        global rms\n",
    "        rms= 0.0\n",
    "        for i in range(0, len(data), 2):\n",
    "            sample = int.from_bytes(data[i:i+2], byteorder=\"little\", signed=True)\n",
    "            rms += sample ** 2\n",
    "        rms /= CHUNK\n",
    "        rms = rms ** 0.5\n",
    "        if c % 4 == 0:\n",
    "                #print(rms)\n",
    "            if rms > 500 and nurse_now == \"n\":\n",
    "                nurse_now = \"o\"\n",
    "                q.put(\"o\")\n",
    "            elif rms < 1000 and nurse_now == \"o\":\n",
    "                nurse_now = \"n\"\n",
    "                q.put(\"n\")\n",
    "                #print(nurse_now)\n",
    "\n",
    "        stream.write(data)\n",
    "        data = wf.readframes(CHUNK)\n",
    "        c += 1\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    q.put(\"end\")\n",
    "        \n",
    "def play_wav():\n",
    "    nurse = canvas.create_image(-scrw/20, 0, anchor=tk.NW, image=nurse_n)\n",
    "    canvas.update()\n",
    "    thread = threading.Thread(target=play_stream)\n",
    "    thread.start()\n",
    "    while True:\n",
    "        #time.sleep(0.016)\n",
    "        if not q.empty():\n",
    "            nurse_now = q.get()\n",
    "            #if nurse_prev != nurse_now :\n",
    "            if nurse_now == \"n\":\n",
    "                canvas.create_image(-scrw/20, 0, anchor=tk.NW, image=nurse_n)\n",
    "                #canvas.itemconfigure(nurse, image=nurse_n)\n",
    "                #print(\"n\")\n",
    "            if nurse_now == \"o\":\n",
    "                canvas.create_image(-scrw/20, 0, anchor=tk.NW, image=nurse_o)\n",
    "                #canvas.itemconfigure(nurse, image=nurse_O)\n",
    "                #nurse_now:canvas.after(8, update_image,nurse_now)  #afteerはこのコードを実行してから8ms後にuipdateが実行される\n",
    "                #print(\"o\")\n",
    "            canvas.update_idletasks()\n",
    "            #canvas.update()\n",
    "            if nurse_now == \"end\":break\n",
    "    canvas.create_image(-scrw/20, 0, anchor=tk.NW, image=nurse_n) \n",
    "    canvas.update_idletasks()\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46c1e65b-cfcd-47b9-ac0e-1d1bd34de423",
   "metadata": {
    "id": "46c1e65b-cfcd-47b9-ac0e-1d1bd34de423"
   },
   "outputs": [],
   "source": [
    "#VOICEVOXのアプリにクエリを飛ばして合成してもらう関数を定義\n",
    "import json\n",
    "import requests\n",
    "def generate_wav(text, speaker = 1, filepath='./audio.wav'):\n",
    "    host = 'localhost'\n",
    "    port = 50021\n",
    "    params = (\n",
    "        ('text', text),\n",
    "        ('speaker', speaker),\n",
    "    )\n",
    "    response1 = requests.post(\n",
    "        f'http://{host}:{port}/audio_query',\n",
    "        params=params\n",
    "    )\n",
    "    headers = {'Content-Type': 'application/json',}\n",
    "    response2 = requests.post(\n",
    "        f'http://{host}:{port}/synthesis',\n",
    "        headers=headers,\n",
    "        params=params,\n",
    "        data=json.dumps(response1.json())\n",
    "    )\n",
    "\n",
    "    wf = wave.open(filepath, 'wb')\n",
    "    wf.setnchannels(1)\n",
    "    wf.setsampwidth(2)\n",
    "    wf.setframerate(24000)\n",
    "    wf.writeframes(response2.content)\n",
    "    wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "159e95fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "def record_audio():\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        try:\n",
    "            print(\"話してください...\")\n",
    "            r.adjust_for_ambient_noise(source)  # ノイズの調整\n",
    "            audio = r.listen(source, timeout=1) # 何秒の沈黙を許すか    \n",
    "            print(\"音声認識結果: \" + r.recognize_google(audio, language='ja-JP'))\n",
    "            return r.recognize_google(audio, language='ja-JP')\n",
    "        except sr.WaitTimeoutError:\n",
    "            #print(\"タイムアウトしました。\")\n",
    "            return \"タイムアウトしました。\"\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"音声を理解できませんでした。\")\n",
    "            return \"音声を理解できませんでした。\" \n",
    "        except sr.RequestError:\n",
    "            print(\"音声認識サービスでエラーが発生しました。\")\n",
    "            return \"音声認識サービスでエラーが発生しました。\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29ca675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "messageCount=0\n",
    "def UpdateMessageLog (text, tag):\n",
    "    global messageCount\n",
    "    messageCount+=1\n",
    "    if messageCount>2:\n",
    "        canvas.move(\"input\", 0, -scrh/4)#会話履歴を上にずらす\n",
    "        canvas.move(\"res\", 0, -scrh/4)\n",
    "#    if len(text) > 39 : text = text[:37] + \"...\"#文字を切るLinux用\n",
    "    if len(text) > 60 : text = text[:58] + \"...\"#文字を切るWindows用\n",
    "    if tag == \"input\":\n",
    "        if messageCount==1:\n",
    "            imagey=scrh*1/4\n",
    "            #print(\"OK\")\n",
    "        else:\n",
    "            imagey=scrh*2/4\n",
    "        canvas.create_image(scrw*77/100, imagey, anchor=tk.N, image=black_box,  tag=tag)\n",
    "        canvas.create_text(\n",
    "            scrw*77/100,\n",
    "            imagey+scrh*3/100,\n",
    "            text=text[:15] + \"\\n\" + text[15:30] + \"\\n\" + text[30:45] + \"\\n\" + text[45:60],\n",
    "            fill=\"white\",\n",
    "            font=(\"HG丸ｺﾞｼｯｸM-PRO\", canvas.winfo_height()//40, \"bold\"),\n",
    "            anchor=\"n\",\n",
    "            tag=tag)\n",
    "    elif tag == \"res\":\n",
    "        canvas.create_image(scrw*62/100, scrh*2/4, anchor=tk.N, image=black_box,  tag=tag)\n",
    "        canvas.create_text(\n",
    "            scrw*62/100,\n",
    "            scrh*(2/4+3/100),\n",
    "            text=text[:15] + \"\\n\" + text[15:30] + \"\\n\" + text[30:45] + \"\\n\" + text[45:60],\n",
    "            fill=\"white\",\n",
    "            font=(\"HG丸ｺﾞｼｯｸM-PRO\", canvas.winfo_height()//40, \"bold\"),\n",
    "            anchor=\"n\",\n",
    "            tag=tag)\n",
    "    print(messageCount)\n",
    "    canvas.update_idletasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e40d1e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2592910511232key_handler'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GUIセットアップ\n",
    "from tkinter import *\n",
    "from PIL import Image, ImageTk, ImageOps\n",
    "import tkinter as tk\n",
    "from tkinter.font import Font\n",
    "\n",
    "# メインウィンドウ生成\n",
    "root = tk.Tk()\n",
    "#root.overrideredirect(True)  # ウィンドウバーを消す#windows用\n",
    "root.iconphoto(False, tk.PhotoImage(file='icon.png'))#by 捨て犬A様 # ウィンドウアイコン設定\n",
    "root.title(\"ナースロボ＿タイプＴ\")\n",
    "#root.attributes('-fullscreen', True)#フルスクリーン\n",
    "\n",
    "root.config(bg=\"black\") # 背景を黒にする#windows用\n",
    "#root.attributes(\"-transparentcolor\", \"black\") # 黒を透過する#windows用\n",
    "#Linuxではウィンドウの\n",
    "\n",
    "# ディスプレイサイズを取得してスクリーンのサイズを決める\n",
    "scrh = int(root.winfo_screenheight()*2/3)\n",
    "scrw = int(scrh*3/2)\n",
    "root.geometry(f\"{scrw}x{scrh}+{root.winfo_screenwidth()-scrw}+{root.winfo_screenheight()*95//100-scrh}\")#windows用\n",
    "#root.geometry(f\"{scrw}x{scrh}+{root.winfo_screenwidth()-scrw}+{root.winfo_screenheight()-scrh}\")#Linux用\n",
    "#root.geometry(f\"{scrw}x{scrh}+{root.winfo_screenwidth()-scrw}+{root.winfo_screenheight()//2-scrh}\")#DualLinux用\n",
    "#root.geometry(f\"{scrw}x{scrh}+0+0\")\n",
    "\n",
    "# ウィンドウを左右に分ける\n",
    "# frame_full = tk.Frame(root)\n",
    "# frame_full.pack(fill=tk.BOTH, expand=True)\n",
    "# frame_left = tk.Frame(root)\n",
    "# frame_left.pack(side=tk.LEFT, expand=True)\n",
    "# frame_right = tk.Frame(root)\n",
    "# frame_right.pack(side=tk.RIGHT, expand=True)\n",
    "\n",
    "# 画像を読み込む\n",
    "nurse_o = Image.open(\"TT_Tachie_o.png\")#by 捨て犬A様\n",
    "nurse_n = Image.open(\"TT_Tachie_n.png\")#by 捨て犬A様\n",
    "alpha = Image.open(\"alpha.png\")\n",
    "back = Image.open(\"icon.png\")#by 捨て犬A様\n",
    "black = Image.open(\"black.png\")\n",
    "box = Image.open(\"massagebox.png\")\n",
    "black_box = Image.open(\"massagebox_black.png\")\n",
    "entryBox = Image.open(\"entryBox.png\")\n",
    "send = Image.open(\"send.png\")\n",
    "send = send.convert('RGBA')\n",
    "\n",
    "# 画像のサイズを調整\n",
    "nurse_height = int(scrh) # 画像の高さをディスプレイの1/3の大きさに指定\n",
    "nurse_width = int(nurse_height*1500/1927) # 高さに横幅を合わせる\n",
    "box_height = int(scrh/5)\n",
    "box_width = int(box_height*1600/500)\n",
    "entryBox_width = int(scrw*55/100)\n",
    "entryBox_height = int(entryBox_width*400/2700*5/6)\n",
    "send_height = int(entryBox_height*80/100)\n",
    "\n",
    "# 画像をリサイズ\n",
    "nurse_o = nurse_o.resize((nurse_width, nurse_height))\n",
    "nurse_n = nurse_n.resize((nurse_width, nurse_height))\n",
    "back = back.resize((scrw, scrh))\n",
    "alpha = alpha.resize((scrw, scrh))\n",
    "black = black.resize((scrw, scrh))\n",
    "box = box.resize((box_width, box_height))\n",
    "black_box = black_box.resize((box_width, box_height))\n",
    "entryBox = entryBox.resize((entryBox_width, entryBox_height))\n",
    "send = send.resize((send_height, send_height))\n",
    "\n",
    "# ImageTkオブジェクトを作成\n",
    "nurse_o = ImageTk.PhotoImage(nurse_o)\n",
    "nurse_n = ImageTk.PhotoImage(nurse_n)\n",
    "back = ImageTk.PhotoImage(back)\n",
    "alpha = ImageTk.PhotoImage(alpha)\n",
    "black = ImageTk.PhotoImage(black)\n",
    "#box = ImageTk.PhotoImage(box)\n",
    "black_box = ImageTk.PhotoImage(black_box)\n",
    "entryBox = ImageTk.PhotoImage(entryBox)\n",
    "send = ImageTk.PhotoImage(send)\n",
    "\n",
    "# キャンバスを作成\n",
    "#canvas = tk.Canvas(frame_full, width=scrw, height=scrh, bg='#101010', highlightthickness=0)\n",
    "canvas = tk.Canvas(root, width=scrw, height=scrh, bg='black', highlightthickness=0)\n",
    "canvas.pack()\n",
    "\n",
    "# Canvasを作成して画像を表示\n",
    "canvas.create_image(scrw/2, scrh/2, image=back, tag=\"back\")\n",
    "canvas.create_image(scrw/2, scrh/2, image=alpha, tag=\"alpha\")\n",
    "canvas.create_image(-scrw/20, 0, anchor=tk.NW, image=nurse_o)\n",
    "nurse = canvas.create_image(-scrw/20, 0, anchor=tk.NW, image=nurse_n, tags=\"n_tag\")\n",
    "canvas.create_image(scrw*62/100, 0, anchor=tk.N, image=black_box, tag=\"res\")\n",
    "canvas.create_image(scrw*72/100, scrh*89/100, anchor=tk.N, image=entryBox)\n",
    "\n",
    "text=\"あなたの言葉を読んだり聞いたりできます。\\nあなたのAPIキーを教えてください。\"\n",
    "canvas.create_text(scrw*62/100, scrh*5/100,text=text[:15] + \"\\n\" + text[15:30] + text[30:45] + \"\\n\" + text[45:60], fill=\"white\", font=(\"HG丸ｺﾞｼｯｸM-PRO\", scrh//40, \"bold\") , anchor=\"n\", tag = \"res\")#windows用\n",
    "#text = canvas.create_text(scrw*62/100, scrh*5/100,text=text[:13] + \"\\n\" + text[13:26] + \"\\n\" + text[26:], fill=\"white\", font=(\"HG丸ｺﾞｼｯｸM-PRO\", scrh//40, \"bold\") , anchor=\"n\", tag = \"res\")#Linux用\n",
    "\n",
    "# font = ('HG丸ｺﾞｼｯｸM-PRO', 14)\n",
    "# label = tk.Label(root, text='ボタンを押してください', font=font, bd=0, highlightthickness=0)\n",
    "# label.configure(bg=root['bg'])\n",
    "# label.place(x=scrw*62//100, y=0)\n",
    "\n",
    "def key_handler(e):\n",
    "    if e.keycode == 13 :#Enterキーでwindows用\n",
    "    #if e.keycode == 36 :#EnterキーでLinux用\n",
    "        clicked_button(canvas)#入力を完了する\n",
    "    elif e.keycode == 27:#9Escキーでwindows用\n",
    "    #elif e.keycode == 9:#9EscキーでLinux用\n",
    "        root.destroy()#ウィンドウを終了する\n",
    "# # Entryウィジェットをメインウィンドウに生成&配4\n",
    "entry = Entry(root, fg=\"white\", width=23, bg=\"#232323\", bd=0, highlightthickness=0, font=(\"HG丸ｺﾞｼｯｸM-PRO\", entryBox_height*3//10, \"bold\"))\n",
    "entry.place(x=scrw*47/100, y=scrh*92/100)\n",
    "entry.bind(\"<KeyPress>\", key_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f84f45b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def is_half_width(text):#imputTextが半角か否かを判定する関数\n",
    "    half_width_chars = string.ascii_letters + string.digits + string.punctuation\n",
    "    for char in text:\n",
    "        if char not in half_width_chars:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# ボタンの動作関数\n",
    "def clicked_button(widget):\n",
    "    global setting\n",
    "    global role\n",
    "    global log\n",
    "    entryText=entry.get()# 入力ボックスの文字列を読み込み\n",
    "    entry.delete(0, \"end\")# 入力ボックスの内容をクリア\n",
    "    if entryText == \"\" and openai.api_key != \"\":#APIキーが入力されるまでは音声認識しない\n",
    "        #音声認識部\n",
    "        while True:\n",
    "            inputText=record_audio()# 音声入力\n",
    "            #print(inputText)\n",
    "            #inputText = inputText.replace('　', '')  # 全角スペースを削除\n",
    "            if inputText == \"タイムアウトしました。\":\n",
    "                pass\n",
    "            elif inputText == \"音声を理解できませんでした。\":\n",
    "                break\n",
    "            elif inputText == \"音声認識サービスでエラーが発生しました。\":\n",
    "                break\n",
    "            else:# 正しく音声認識できた時\n",
    "                print(\"OK\")\n",
    "                break\n",
    "            canvas.update_idletasks()\n",
    "    else :#APIキーが空かテキスト入力された時\n",
    "        inputText = entryText\n",
    "    UpdateMessageLog(inputText, \"input\")#ユーザーの発言内容表示\n",
    "    # 応答検討部\n",
    "    if setting == True:#セッティングモードの時\n",
    "        role = inputText\n",
    "        setting = False\n",
    "        res = \"人格設定を変更しました。\"\n",
    "    else:# セッティングモードでないとき\n",
    "        if inputText == \"/setting\":\n",
    "    #         canvas = tk.Canvas(root, width=scrw, height=scrh, bg='black', highlightthickness=0)\n",
    "    #         canvas.pack()\n",
    "    #         canvas.itemconfigure(\"alpha\", state=\"hidden\")\n",
    "    #         canvas.itemconfigure(\"back\", state=\"hidden\")\n",
    "    #         root.overrideredirect(True)  # ウィンドウバーを消す#windows用\n",
    "    #         root.attributes(\"-transparentcolor\", \"black\") # 黒を透過する#windows用\n",
    "    #         canvas.update_idletasks()\n",
    "            res = \"私の人格の設定文を入力してください。ただし、会話のたびに設定文の長さ分トークンを消費するのでご注意ください。\"\n",
    "            setting = True#セッティングモードを開始\n",
    "        elif inputText == \"\":#inputTextが空でAPIキーも未入力の時\n",
    "            res = \"APIキーを入力してください\"\n",
    "        elif openai.api_key == \"\":# APIキーが未入力の時inutTextの中身はAPIキーの候補\n",
    "            if is_half_width(inputText):\n",
    "                openai.api_key = inputText# APIキーを読み込む\n",
    "                res = \"\"# APIキー検証のためにクリア\n",
    "                try:\n",
    "                    res = openai.ChatCompletion.create(\n",
    "                        model=\"gpt-3.5-turbo\",\n",
    "                        messages=[{\"role\": \"user\",\"content\": inputText},],\n",
    "                        max_tokens=1,\n",
    "                    )\n",
    "                    res = \"APIキーを認識しました。\"\n",
    "                    print(res)\n",
    "                except openai.error.AuthenticationError as error:\n",
    "                    openai.api_key = \"\"# 有効ではないAPIキーをクリア\n",
    "                    res = \"そのAPIキーは有効ではありません。再度入力をお願いします。\"\n",
    "                    print(res)            \n",
    "                print(\"半角文字です\")\n",
    "            else:\n",
    "                print(\"半角文字ではありません\")\n",
    "                res = \"APIキーは半角です。\"\n",
    "        elif inputText == \"音声を理解できませんでした。\":\n",
    "            res = \"ノイズが大きいか発音が不明瞭なため、何と言っているか聞き取れませんでした。\"\n",
    "        elif inputText == \"音声認識サービスでエラーが発生しました。\":\n",
    "            res = \"外部音声認識サービスへのアクセスに失敗しました。\"\n",
    "        else:#まったくエラーが無く、APIキーがあるとき\n",
    "            #対話生成部\n",
    "            res = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\",\"content\": role},\n",
    "                    #{\"role\": \"assistant\",\"content\": log},#前回の対話を引き継ぎ\n",
    "                    {\"role\": \"user\",\"content\": inputText},\n",
    "                ],\n",
    "            )\n",
    "            res = res[\"choices\"][0][\"message\"][\"content\"]\n",
    "            # ここまで--------------------------------\n",
    "            print(res)\n",
    "            log += inputText\n",
    "            log += res\n",
    "            #print(log)\n",
    "    #         disp_text = res# 対話内容表示\n",
    "    #         text = tk.Label(frame_right, text=disp_text, anchor=tk.NE, wraplength=scrw/4)\n",
    "    #         text.pack()\n",
    "            #time.sleep(1)\n",
    "    #        res = inputText#ボイチェン（アニメーション動作確認用）    \n",
    "    \n",
    "    UpdateMessageLog(res, \"res\")#アシスタントの発言内容表示\n",
    "    #音声合成部\n",
    "    speaker = 47#14\n",
    "    generate_wav(res,speaker)\n",
    "    play_wav()\n",
    "    print(\"会話終了\")#標準出力もできる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac3c2f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = \"ご主人様を好きなメイドとして、ご主人様に対する返答をしてください。\"\n",
    "setting = False\n",
    "log = \"\"\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "551322fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pyinstaller nurse-robo.py --onefile\n",
    "\n",
    "#!pyinstaller nurse-robo.spec\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
